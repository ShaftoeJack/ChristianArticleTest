# File Usage Guide for Analysis Phases (3-5)

## üö® **CRITICAL CONTEXT EFFICIENCY GUIDELINES** üö®

### **File Processing Priority Rules**

#### **‚úÖ USE THESE FILES (Context Efficient)**
```
Working_Docs/phase2_citations/downloaded_articles/
‚îú‚îÄ‚îÄ citation_XXX_Author_Year.txt  ‚Üê **USE THESE FOR ALL ANALYSIS**
‚îî‚îÄ‚îÄ citations_database.sqlite      ‚Üê **QUERY THIS FOR CITATIONS**
```

#### **‚ùå AVOID THESE FILES (Context Wasteful)**
```
Working_Docs/phase2_citations/downloaded_articles/
‚îú‚îÄ‚îÄ citation_XXX_Author_Year.pdf  ‚Üê **NEVER USE - WASTE OF CONTEXT**
‚îî‚îÄ‚îÄ citations_index.json          ‚Üê **LEGACY FILE - TOO LARGE**
```

---

## **Detailed File Usage Instructions**

### **üìÑ Text Files (.txt) - PRIMARY SOURCES**
**Location**: `Working_Docs/phase2_citations/downloaded_articles/*.txt`
**Count**: 17 processed articles
**Usage**: Direct content analysis for all phases

**Why Use TXT Files**:
- ‚úÖ **Pre-processed**: Clean text extraction already completed
- ‚úÖ **Context optimized**: Smaller file sizes, faster loading
- ‚úÖ **Analysis ready**: Formatted for computational processing
- ‚úÖ **Quality verified**: All extractions rated "Excellent"

**File Naming Convention**:
```
citation_003_A_2020.txt          ‚Üê Allen et al. 2020
citation_010_Angielczyk_2017.txt ‚Üê Angielczyk & Kammerer 2017
citation_012_Angielczyk_2017.txt ‚Üê Angielczyk et al. 2017 (Sangusaurus)
citation_013_Angielczyk_2021.txt ‚Üê Angielczyk et al. 2021 (Kunpania)
... (all 17 files follow this pattern)
```

### **üóÑÔ∏è SQLite Database - CITATION QUERIES**
**Location**: `Working_Docs/phase2_citations/citations_database.sqlite`
**Records**: 578 citations with complete metadata
**Usage**: Efficient citation lookups without loading massive JSON

**Key Benefits**:
- ‚úÖ **Context efficient**: Query specific citations only
- ‚úÖ **Fast searches**: Indexed database vs. linear JSON parsing
- ‚úÖ **Flexible queries**: SQL for complex analysis needs
- ‚úÖ **Selective loading**: Get only what you need when you need it

**Common Query Examples**:
```sql
-- Get top 15 priority citations
SELECT * FROM citations WHERE top_15_priority = 1 ORDER BY priority_score DESC;

-- Find citations by specific author
SELECT * FROM citations WHERE authors LIKE '%Angielczyk%';

-- Get recent publications
SELECT * FROM citations WHERE year >= 2018 ORDER BY year DESC;

-- Find citations with DOIs
SELECT * FROM citations WHERE doi_available = 1;
```

### **üìÅ PDF Files - AVOID IN ANALYSIS PHASES**
**Location**: `Working_Docs/phase2_citations/downloaded_articles/*.pdf`
**Status**: Archive only - do not process
**Reason**: Context inefficient when TXT alternatives exist

**Why Avoid PDFs**:
- ‚ùå **Context waste**: Large file sizes consume unnecessary space
- ‚ùå **Processing overhead**: Require additional extraction steps
- ‚ùå **Redundant**: TXT files already contain the same content
- ‚ùå **Analysis inefficient**: Not optimized for computational processing

---

## **Phase-Specific Usage Guidelines**

### **Phase 3: Preliminary Analysis**
**Primary Sources**:
- `Working_Docs/phase1_ingestion/article_text.txt` (main article)
- `Working_Docs/phase2_citations/downloaded_articles/*.txt` (background literature)
- SQLite queries for citation context

**Workflow**:
1. Read main article for comprehensive understanding
2. Query database for priority citations: `SELECT * FROM citations WHERE top_15_priority = 1`
3. Read relevant TXT files for background context
4. Cross-reference using citation IDs for systematic analysis

### **Phase 4: Deep Sectional Analysis**
**Primary Sources**:
- `Working_Docs/phase1_ingestion/article_text.txt` (section-by-section analysis)
- Selected TXT files based on section relevance
- SQLite queries for methodology and comparative studies

**Workflow**:
1. Analyze main article sections systematically
2. Query for relevant citations: `SELECT * FROM citations WHERE category = 'methodological'`
3. Read corresponding TXT files for technical context
4. Cross-reference findings with comparative studies

### **Phase 5: Synthesis & General Audience Translation**
**Primary Sources**:
- All previous phase outputs
- Selected TXT files for significance validation
- SQLite queries for foundational and recent developments

**Workflow**:
1. Synthesize findings from all previous phases
2. Query for foundational work: `SELECT * FROM citations WHERE introduction_mention = 1`
3. Validate significance claims against literature
4. Create accessible explanations using background context

---

## **Quick Reference Commands**

### **SQLite Database Queries**
```bash
# Command line access
sqlite3 Working_Docs/phase2_citations/citations_database.sqlite

# Python utility (if available)
python Working_Docs/phase2_citations/citations_query.py stats
python Working_Docs/phase2_citations/citations_query.py top --limit 15
```

### **File Counting**
```bash
# Count available TXT files
ls Working_Docs/phase2_citations/downloaded_articles/*.txt | wc -l

# Check specific citation file
ls Working_Docs/phase2_citations/downloaded_articles/citation_289_*
```

### **Cross-Reference Lookup**
```sql
-- Find file for specific citation ID
SELECT id, authors, year, title FROM citations WHERE id = 289;

-- Result tells you to look for: citation_289_King_1988.txt
```

---

## **Context Window Management**

### **Best Practices**
1. **Query first**: Use SQLite to identify relevant citations before reading files
2. **Read selectively**: Only load TXT files needed for current analysis step
3. **Batch efficiently**: Group related citations for single reading session
4. **Cross-reference systematically**: Use citation IDs to maintain organization

### **Efficiency Gains**
- **50% size reduction**: SQLite vs. JSON for citation data
- **Targeted loading**: Read 1-3 TXT files vs. entire literature collection
- **Query precision**: Get exactly the citations needed for current analysis
- **Context preservation**: More space for actual analysis vs. data loading

---

## **Error Prevention**

### **Common Mistakes to Avoid**
‚ùå Loading PDF files when TXT alternatives exist
‚ùå Loading entire citations_index.json file
‚ùå Reading all 17 TXT files simultaneously
‚ùå Ignoring the SQLite database for citation lookups

### **Recommended Approach**
‚úÖ Start with SQLite query to identify relevant citations
‚úÖ Read specific TXT files based on analysis needs
‚úÖ Use citation IDs for systematic cross-referencing
‚úÖ Maintain efficient context window usage throughout

---

## **File Inventory Summary**

### **Available for Analysis (Context Efficient)**
- **Main Article**: `article_text.txt` (100,494 words)
- **Literature**: 17 TXT files (processed background sources)
- **Citation Database**: SQLite with 578 records
- **Cross-Reference**: File mapping and documentation

### **Archive Only (Context Inefficient)**
- **PDF Files**: 17 PDF files (keep for reference, don't analyze)
- **Legacy JSON**: `citations_index.json` (superseded by SQLite)

### **Total Analysis Capacity**
With efficient file usage, you have comprehensive coverage of:
- **Primary research**: Complete dicynodont fossil study
- **Literature foundation**: 17 key research papers
- **Citation context**: 578 background references
- **Systematic organization**: All cross-referenced and queryable

**Ready for efficient, comprehensive analysis across Phases 3-5!**